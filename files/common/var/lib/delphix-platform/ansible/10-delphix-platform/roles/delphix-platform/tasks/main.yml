#
# Copyright 2018, 2019 Delphix
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

---
#
# We use a non-standard directory for the appliance user's home
# directory. As a result, we have to explicitly create the "base
# directory" here, rather than rely on Ansible's user module to create
# it below; otherwise that task will fail.
#
- file:
    path: /export/home
    state: directory
    mode: 0755

- user:
    name: delphix
    uid: 65433
    group: staff
    groups: root
    shell: /bin/bash
    create_home: yes
    comment: Delphix User
    home: /export/home/delphix

#
# In order for this locale to be used (e.g. by virtualization) we need
# to ensure it's available. Generally this locale will be generated by
# appliance-build for new VMs, but we can't rely on that since that
# doesn't work for not-in-place upgrades. Thus, we must explicitly
# generate the locale here.
#
- locale_gen:
    name: en_US.UTF-8
    state: present

#
# If we don't disable the "OS prober" script, when we update the grub
# configuration, it may find OS installations that we don't want. For
# example, when updating grub from within the chroot environment, it may
# find the OS installed on the build server's disks, since we bind mount
# the host's /dev directory into the chroot environment. By disabling
# the "OS prober" script, we avoid this issue.
#
- file:
    path: /etc/grub.d/30_os-prober
    mode: 0644

#
# Create a world writeable directory for application and kernel core
# dumps. We want it world writeable because we're sharing one directory
# for corefiles from any user. Unlike illumos where all appliacation
# cores are written out as the root user, linux cores are written with
# the UID of the running process.
#
- file:
    path: /var/crash
    state: directory
    mode: 0777

#
# Create the directory and ZFS dataset that we'll use to store unpacked
# upgrade images. This directory is used by the upgrade related scripts
# found in this directory, but also used by upgrade-scripts stored in
# the appliace-build repository (which generates the upgrade image).
# Thus, we need to be careful if/when changing this, as we'll need to
# coordinate the change with the appliance-build upgrade-scripts.
#
- file:
    path: /var/dlpx-update
    state: directory

#
# The zfs module cannot be run from the chroot environment that's used
# by appliance-build. Thus, we disable this when run in that context by
# only running this when ansible_is_chroot is not true.
#
- zfs:
    name: rpool/update
    state: present
    extra_zfs_properties:
      mountpoint: /var/dlpx-update
      compression: gzip
      quota: 30g
  when: not ansible_is_chroot

#
# Create the directory and ZFS dataset that we'll use to store upgrade
# related logs (that need to be shared across versions). This directory is
# used  part of upgrade verify and rollback process to share log files to
# older version. Thus, we need to be careful if/when changing this, as we'll
# need to coordinate the change with the appliance-build upgrade-scripts.
#
- file:
    path: /var/tmp/delphix-upgrade
    state: directory

- zfs:
    name: rpool/upgrade-logs
    state: present
    extra_zfs_properties:
      mountpoint: /var/tmp/delphix-upgrade
      compression: gzip
  when: not ansible_is_chroot

#
# Configure command audit logging
#
# We want to record all commands executed on the appliance. Opt out for
# setsid since all ExecuteUtils.execute wrap each call with setsid.
#
- lineinfile:
    path: /etc/audit/auditd.conf
    regexp: "{{ item.regex }}"
    line: "{{ item.line }}"
  with_items:
    - { regex: "^num_logs =", line: "num_logs = 6" }
    - { regex: "^max_log_file =", line: "max_log_file = 3072" }
    - { regex: "^max_log_file_action =", line: "max_log_file_action = rotate" }
    - { regex: "^log_format =", line: "log_format = RAW" }

- blockinfile:
    path: /etc/audit/rules.d/audit.rules
    insertafter: EOF
    block: |
      ## Record all executed commands (excluding setsid)
      -a exit,never -S execve -F exe=/usr/bin/setsid
      -a exit,always -S execve

      ## Record command exit failures (execve result is not command result)
      -a exit,always -F a0!=0 -S exit_group
      -a exit,always -F a0!=0 -S exit

#
# Prevent auditd output from being duplicated into the journal. The size
# of the journal is limited and the high volume of messages from auditd
# would end up causing important messages from less verbose services to
# be flushed and lost prematurely.
#
- command: systemctl mask systemd-journald-audit.socket

#
# By default, the ulimit for core files is set to 0, and the default
# filename and location for a core file is 'core' in the cwd. Update
# limits.conf to allow processes running as root or a regular user to
# make core files.
#
- lineinfile:
    create: yes
    path: /etc/security/limits.conf
    line: "{{ item }} soft core unlimited"
  with_items:
    - 'root'
    - '*'

- lineinfile:
    path: /etc/ssh/sshd_config
    regexp: "^#?{{ item.key }} "
    line: "{{ item.key }} {{ item.value }}"
  with_items:
    #
    # Configure SSH to allow PAM "conversations" (interactions with the user).
    #
    - { key: "ChallengeResponseAuthentication", value: "yes" }
    #
    # Harden the appliance by disabling ssh-agent(1), tcp, UNIX domain, and
    # X11 forwarding. Note that this doesn't improve security unless users are
    # also denied shell access.
    #
    - { key: "AllowAgentForwarding", value: "no" }
    - { key: "AllowStreamLocalForwarding", value: "no" }
    - { key: "AllowTcpForwarding", value: "no" }
    - { key: "X11Forwarding", value: "no" }

#
# The CRA project mandated a 30 minute timeout for any idle connections.
# By enabling an inactivity timeout we ensure that idle connections are
# closed. Thus any sessions that are accidentally left opened at a
# customer site will timeout preventing customers from gaining access to
# our engine.
#
- set_fact:
    ssh_client_alive_interval: "1800"

#
# With that said (see comment above), the Azure marketplace does not
# allow a value greater than 3 minutes. So, when running on Azure, we
# use 3 minutes.
#
- set_fact:
    ssh_client_alive_interval: "180"
  when: platform == "azure"

- lineinfile:
    path: /etc/ssh/sshd_config
    regexp: "^#?{{ item.key }} "
    line: "{{ item.key }} {{ item.value }}"
  with_items:
    - { key: "ClientAliveInterval", value: "{{ ssh_client_alive_interval }}" }
    - { key: "ClientAliveCountMax", value: "0" }
  when:
    #
    # For developer convenience, we only enable the CRA mandated timeout
    # for external variants. The idle timeout can be a burden when we
    # need to run long running processes over SSH on our internal
    # systems (e.g. for development, testing, etc).
    #
    - variant is regex("external-.*")

#
# Harden the appliance by disabling SFTP.
#
- replace:
    path: /etc/ssh/sshd_config
    regexp: '^(Subsystem.*sftp.*)'
    replace: '#\1'

#
# Ssh leads to the CLI, not bash, so let's remove all the linuxy shell goodies,
# like last-login, "welcome to ubuntu", and help messages. This makes linux and
# illumos look the same, too.
#
- replace:
    dest: /etc/ssh/sshd_config
    regexp: '^#?[\s]*PrintLastLog.*$'
    replace: 'PrintLastLog no'
- replace:
    dest: /etc/pam.d/sshd
    regexp: '^(session[\s]+optional[\s]+pam_motd\.so.*)$'
    replace: '#\1'

#
# Enable SNMP client tools to load MIBs by default.
#
- replace:
    path: /etc/snmp/snmp.conf
    regexp: '^(mibs\s+:\s+)'
    replace: '#\1'

- lineinfile:
    path: /etc/environment
    regexp: '^{{ item.key }}='
    line: '{{ item.key }}="{{ item.value }}"'
  with_items:
    - { key: 'JAVA_HOME', value: '/usr/lib/jvm/adoptopenjdk-java8-jdk-amd64' }

#
# Configure the Azure agent. Only run this on Azure, since that is the
# only platform that has the Azure agent installed.
#
- lineinfile:
    path: /etc/waagent.conf
    regexp: '^{{ item.key }}='
    line: '{{ item.key }}={{ item.value }}'
  with_items:
    #
    # We use cloud-init rather than the Azure agent to handle any
    # provisioning logic that we need.
    #
    - { key: 'Provisioning.Enabled', value: 'n' }
    #
    # Even though we do use cloud-init to handle some provisioning
    # tasks, we should tell the Azure agent that we don't. Otherwise,
    # the Azure agent will wait for cloud-init to complete before
    # reporting back to Azure that the VM is running. The way it detects
    # that cloud-init has finished is by waiting for cloud-init to copy
    # a certain file (ovf-env.xml) into /var/lib/waagent/, but
    # cloud-init won't copy this file unless it has been configured to
    # read Azure userdata (as determined by the 'datasource_list'
    # parameter). We do not allow the appliance to read userdata from
    # any source, at least on the external variant, with the result that
    # the agent waits 20+ minutes before timing out and finally
    # reporting the VM as running.
    #
    - { key: 'Provisioning.UseCloudInit', value: 'n' }
    #
    # Prevent customers from running arbitrary code on the engine via
    # extensions when they deploy.
    #
    - { key: 'Extensions.Enabled', value: 'n' }
    #
    # This controls auto-updating of the extension handler (not the
    # provisioning handler or daemon). It seems safer to disable this
    # rather than to allow Microsoft to push new code to our engines,
    # especially since we aren't using any extensions.
    #
    - { key: 'AutoUpdate.Enabled', value: 'n' }
  when: platform == "azure"

#
# Customize the GCP linux environment.
#
# Update the override file for the GCP instance. This file gets
# applied dynamically by running google_instance_setup script.
#
- blockinfile:
    path: /etc/default/instance_configs.cfg.template
    create: yes
    block: |
      #
      # Disable the accounts daemon to prevent adding/removing
      # users on the engine.
      #
      [Daemons]
      accounts_daemon = false

      #
      # Disable user supplied startup/shutdown scripts from running on
      # the engine.
      #
      [MetadataScripts]
      shutdown = false
      startup = false
  when:
    - platform == "gcp"
  notify: "gcp config changed"

#
# Make sure that the account daemon is always disabled. The override file
# above should prevent this and this is designed to catch any corner cases.
#
- command: systemctl disable google-accounts-daemon.service
  when:
    - platform == "gcp"

#
# We want the ssh service to start as early as possible during boot up,
# so we explicitly remove all dependencies of the service here. We've
# configured the service not to use the "default" dependencies, via the
# "override.conf" file in the delphix-platform package. Unfortuantely
# though, we can't remove any dependencies specified using "After=" in
# the original SSH service file, by using that same "override.conf"
# file. Thus, to remove the "After=" dependencies, we have to create a
# completely new unit definition for the SSH service, that will override
# the original unit definition; Systemd allows us to use files in
# "/etc/systemd" to replace files in "/lib/systemd".
#
# So, the strategy here is to copy the original unit definition from
# "/lib/systemd" (the file is provided by the SSH package) to
# "/etc/systemd", and then modify the copy to remove the "After=" line.
# This way, if the original unit definitation is changed on upgrade,
# we'll automatically use the new file from the new package; but we'll
# still be able to modify the file to remove the "After=" dependencies.
# Additionally, we don't modify the file in "/lib/systemd" directly, so
# that we don't break "debsums -c", and it's easy to "revert" our
# changes by simply removing our copy in "/etc/systemd".
#
- copy:
    remote_src: yes
    src: /lib/systemd/system/ssh.service
    dest: /etc/systemd/system/ssh.service
    owner: root
    group: root
    mode: 0644

- lineinfile:
    path: /etc/systemd/system/ssh.service
    regexp: "^After="
    state: absent

#
# In addition to removing the SSH service dependencies (done above), we
# also want to disable pam_nologin. Otherwise, SSH will come up quickly,
# but we won't be able to log in immediately, due to pam_nologin.
#
- lineinfile:
    dest: '/etc/pam.d/{{ item }}'
    regexp: '^#?(.*)(pam_nologin.so)(.*)$'
    line: '#\1\2\3'
    backrefs: yes
    state: present
  with_items:
    - login
    - sshd

#
# On Xen, block devices, including cdroms, are named with the scheme /dev/xvdX.
# Thus, the udev rules for cdroms are written to match devices with that naming
# scheme. These rules cause 'cdrom_id' to run, and when it does, it opens the
# device with the O_EXCL flag. On rare occasions, 'zpool create' will be
# attempting to label the same device at the same time. 'zpool' also uses O_EXCL
# when it tries to open the device, so its attempt will fail with EBUSY.
#
# This removes 'xvd*' from the list of matching names in 60-cdrom_id.rules by
# overriding the original version of the file in /lib/ with a modified one in
# /etc/.
#
- copy:
    remote_src: yes
    src: /lib/udev/rules.d/60-cdrom_id.rules
    dest: /etc/udev/rules.d/60-cdrom_id.rules
    owner: root
    group: root
    mode: 0644
- lineinfile:
    path: /etc/udev/rules.d/60-cdrom_id.rules
    backrefs: yes
    regexp: '(.*)\|xvd\*(.*)'
    line: '\1\2'

#
# The default udev rules create two different by-id links for each storage
# device on ESX, based the same serial number but with different prefixes.
# The first is based on the bus type (scsi) and the second is a catch-all
# "World Wide Name" (wwn). After migration, we import domain0 with the
# "/dev/disk/by-id" path, but since udev runs asynchronously, we may end up
# with a mix of wwn and scsi aliases. This causes problems when the DE tries to
# match devices on the system to those in the pool, i.e. for removal.
#
# This moves the wwn links to the /dev/disk/by-id/wwn sub-directory, keeping it
# available as a backup but limiting the /dev/disk/by-id namespace to one type
# of id. We override the original rules in /lib/ with our new version in /etc/.
#
- copy:
    remote_src: yes
    src: /lib/udev/rules.d/60-persistent-storage.rules
    dest: /etc/udev/rules.d/60-persistent-storage.rules
    owner: root
    group: root
    mode: 0644
- replace:
    path: /etc/udev/rules.d/60-persistent-storage.rules
    regexp: 'disk\/by-id\/wwn-'
    replace: 'disk/by-id/wwn/'

#
# Enable CRA for external variants
#
- command: pam-auth-update {{ item }}
  with_items:
  - --enable challenge-response
  - --remove unix
  when:
    - variant is regex("external-.*")

#
# Increase login timeout to give support more time to interact with CRA via the console.
#
- lineinfile:
    path: /etc/login.defs
    regexp: '^LOGIN_TIMEOUT[\t ]*\d*$'
    line: 'LOGIN_TIMEOUT    300'

#
# MAKEDUMP_ARGS - Configure makedumpfile to:
#       [1] Compress the dump (-c)
#       [2] Filter out pages that are zero, in the page or private cache,
#           part of user data, or marked as freed (-d 31)
#       [3] Print common, error, and report messages (--message-level 22)
#       [4] Exclude ZFS ARC file data pages
#           (--private-page-filter 0x2F5ABDF11ECAC4E)
#       * see man page makedumpfile(8) for more info
#
# KDUMP_CMDLINE_APPEND - We first append the default parameters passed
#       by the kdump-tools package:
#       [1] Force drivers to reset the underlying device during
#           initialization (reset_devices)
#       [2] Run the kdump-tools-dump service that will invoke
#           makedumpfile (systemd.unit=kdump-tools-dump.service)
#       [3] We don't intend to use multithreaded programs in the
#           crash kernel, so in order to save some memory we specify
#           the number of CPUs to be 1 (nr_cpus=1)
#       [4] Reduce driver initialization failures due to shared
#           interrupts in the crash kernel by searching all
#           handlers when an interrupt is not handled (irqpoll)
#       [5] Disable the USB subsystem as we won't be needing it
#           (nousb)
#       [6] Allow the standard Linux storage driver to function
#           when running on Hyper-V, otherwise kexec'ing a new
#           kernel doesn't work (ata_piix.prefer_ms_hyperv=0)
#           See the following link for more info:
#           https://support.microsoft.com/ca-es/help/2858695
#
#       Then we go ahead and append our own options on top of the
#       defaults:
#       [1] If the crash-kernel panics too we don't want to be
#           stuck there forever. Ensure we reboot when that
#           happens after 10 seconds (panic=10)
#
#       * all of the above can be found in
#         Documentation/admin-guide/kernel-parameters.txt and
#         Documentation/kdump/kdump.txt of the Linux Kernel repo.
#
- lineinfile:
    path: /etc/default/kdump-tools
    regexp: "{{ item.regex }}"
    line: "{{ item.line }}"
  with_items:
    - regex: '^#?MAKEDUMP_ARGS='
      line: 'MAKEDUMP_ARGS="-c -d 31 --message-level 22 --private-page-filter 0x2F5ABDF11ECAC4E"'
    - regex: '^#?KDUMP_CMDLINE_APPEND='
      line: 'KDUMP_CMDLINE_APPEND="reset_devices systemd.unit=kdump-tools-dump.service nr_cpus=1 irqpoll nousb ata_piix.prefer_ms_hyperv=0 panic=10"'

#
# Disable all motd scripts except for those provided by Delphix by removing
# executable permissions on every script in /etc/update-motd.d except those
# that have "-delphix" in their filename.
#
- find:
    paths: /etc/update-motd.d
    excludes: '*-delphix*'
  register: motd_files

- file:
    path: "{{ item.path }}"
    mode: 0644
  with_items: '{{ motd_files.files }}'
